{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNNYzvHamHK8EonIDgkjYue",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cksdud123/colab/blob/main/Anomaly_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9txvg8qHqg8",
        "outputId": "643d516e-68c6-448e-ee10-aab30d2464ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications import VGG16\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dropout\n",
        "import random\n",
        "from skimage.metrics import structural_similarity as ssim"
      ],
      "metadata": {
        "id": "QleTQ3ilJm90"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정상 데이터\n",
        "train_dir = glob.glob('/content/drive/MyDrive/Colab Notebooks/mvtec_anomaly_detection/bottle/train/good/*')\n",
        "# 이상 데이터들\n",
        "test_dir = glob.glob('/content/drive/MyDrive/Colab Notebooks/mvtec_anomaly_detection/bottle/test/broken_large/*')\n",
        "test_dir_broken_small = glob.glob('/content/drive/MyDrive/Colab Notebooks/mvtec_anomaly_detection/bottle/test/broken_small/*')\n",
        "test_dir_contamination = glob.glob('/content/drive/MyDrive/Colab Notebooks/mvtec_anomaly_detection/bottle/test/contamination/*')\n",
        "\n",
        "# 정상 테스트 데이터\n",
        "test_dir_good = glob.glob('/content/drive/MyDrive/Colab Notebooks/mvtec_anomaly_detection/bottle/test/good/*')"
      ],
      "metadata": {
        "id": "PDuMwtPDIeFt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = []\n",
        "train_labels = []\n",
        "test_images = []\n",
        "test_labels = []\n",
        "test_images_good = []\n",
        "test_labels_good = []\n",
        "target_size = (224, 224)"
      ],
      "metadata": {
        "id": "5_rt4czDPzj6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정상 데이터가 들어있는 훈련용 데이터세트\n",
        "train_dir = train_dir\n",
        "# 이상 데이터가 들어있는 훈련용 데이터세트\n",
        "test_dir = test_dir + test_dir_broken_small + test_dir_contamination\n",
        "# 정상 데이터만 들어가있는 테스트용 데이터세트\n",
        "test_dir_good = test_dir_good"
      ],
      "metadata": {
        "id": "nzHcFyIb1C7A"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 내의 모든 이미지 파일에 대해 resize 작업과 픽셀 값 정규화 작업\n",
        "# 이미지 로드 및 리사이징\n",
        "for img_path in train_dir:\n",
        "    img = Image.open(img_path)\n",
        "    rgb_img = img.convert('RGB')\n",
        "    resized_img = rgb_img.resize(target_size)\n",
        "    img_array = np.array(resized_img)\n",
        "    min_value = img_array.min()\n",
        "    max_value = img_array.max()\n",
        "    normalized_img_array = (img_array - min_value) / (max_value - min_value)\n",
        "    train_images.append(normalized_img_array)\n",
        "    train_labels.append(0)\n",
        "#test_dir_broken_small + test_dir_contamination\n",
        "for img_path in test_dir + test_dir_broken_small + test_dir_contamination:\n",
        "    img = Image.open(img_path)\n",
        "    rgb_img = img.convert('RGB')\n",
        "    resized_img = rgb_img.resize(target_size)\n",
        "    img_array = np.array(resized_img)  # 수정: img_array 대신 resized_img를 사용\n",
        "    min_value = img_array.min()\n",
        "    max_value = img_array.max()\n",
        "    normalized_img_array = (img_array - min_value) / (max_value - min_value)\n",
        "    test_images.append(normalized_img_array)\n",
        "    test_labels.append(1)"
      ],
      "metadata": {
        "id": "pTuytKxRV19K"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img_path in test_dir_good:\n",
        "    img = Image.open(img_path)\n",
        "    rgb_img = img.convert('RGB')\n",
        "    resized_img = rgb_img.resize(target_size)\n",
        "    img_array = np.array(resized_img)\n",
        "    min_value = img_array.min()\n",
        "    max_value = img_array.max()\n",
        "    normalized_img_array = (img_array - min_value) / (max_value - min_value)\n",
        "    test_images_good.append(normalized_img_array)\n",
        "    test_labels_good.append(0)"
      ],
      "metadata": {
        "id": "YsN7Ekzwv2fl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤 시드 설정\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# 정상과 비정상 데이터를 합친 전체 데이터셋\n",
        "all_images = train_images + test_images\n",
        "all_labels = train_labels + test_labels\n",
        "# 테스트를 위한 정상 데이터세트가 들어있는 데이터셋\n",
        "test_dir_good\n",
        "# 데이터를 훈련 세트와 검증 세트로 분리\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(all_images,\n",
        "                                                                      all_labels,\n",
        "                                                                      test_size=0.2,\n",
        "                                                                      random_state=42)"
      ],
      "metadata": {
        "id": "B77j5dVankMv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy배열로 변환\n",
        "train_images = np.array(train_images)\n",
        "val_images = np.array(val_images)\n",
        "train_labels = np.array(train_labels)\n",
        "val_labels = np.array(val_labels)"
      ],
      "metadata": {
        "id": "hT2O8q7GpBgE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 수 (이진 분류 - 정상: 0, 비정상: 1)\n",
        "num_classes = 1\n",
        "# ResNet-50 모델 불러오기 (pre-trained 가중치 사용)\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# 새로운 fully connected layer 추가하기\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(2, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # 드롭아웃 적용 (0.5는 드롭아웃 비율로 50%의 뉴런을 랜덤하게 비활성화)\n",
        "predictions = Dense(num_classes, activation='sigmoid')(x)  # 이진 분류이므로 activation을 sigmoid로 변경\n",
        "\n",
        "# 전체 모델 정의하기\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "fFm77G3a7o2-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존의 ResNet-50 모델 가중치 동결하기\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 모델 컴파일하기\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "A6acaW3F7xFl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 훈련하기\n",
        "epochs = 10\n",
        "history = model.fit(train_images, train_labels, epochs=epochs, validation_split=0.2)\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l-J8UKP8z3o",
        "outputId": "a825d0ad-2d78-4505-de9b-cc04ece472fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 175s 25s/step - loss: 0.6931 - accuracy: 0.6468 - val_loss: 0.6930 - val_accuracy: 0.6863\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 176s 26s/step - loss: 0.6930 - accuracy: 0.6468 - val_loss: 0.6929 - val_accuracy: 0.6863\n",
            "Epoch 3/10\n",
            "3/7 [===========>..................] - ETA: 1:21 - loss: 0.6930 - accuracy: 0.6250"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 결과를 기록한 history 객체에서 Loss와 Accuracy 추출\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Epoch 수\n",
        "epochs_range = range(1, epochs + 1)\n",
        "\n",
        "# Loss 그래프\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Accuracy 그래프\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs_range, accuracy, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_accuracy, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b7e9HFzAxguU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_images 는 현재 학습된 데이터들중 하나를 선택\n",
        "# test_images 는 현재 학습되지 않은 데이터중 하나를 선택\n",
        "train_ori_images = [img for img, label in zip(all_images, all_labels) if label == 0]\n",
        "train_anomaly_images = [img for img, label in zip(all_images, all_labels) if label == 1]\n",
        "\n",
        "# 모든 훈련 데이터가 들어가있는 데이터셋\n",
        "train_ori_images = train_ori_images + train_anomaly_images\n",
        "\n",
        "test_images = [img for img, label in zip(test_images_good, test_labels_good) if label == 0]\n",
        "\n",
        "print(len(train_ori_images))"
      ],
      "metadata": {
        "id": "XJb4RWd1BLlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_images(image1, image2):\n",
        "    # 이미지를 그레이스케일로 변환\n",
        "    gray_image1 = np.mean(image1, axis=2)\n",
        "    gray_image2 = np.mean(image2, axis=2)\n",
        "\n",
        "    # 이미지 비교\n",
        "    (score, _) = ssim(gray_image1, gray_image2, full=True)\n",
        "    return score\n",
        "\n",
        "# 두 개의 이미지 비교\n",
        "def classify_images(image1, image2):\n",
        "    similarity_score = compare_images(image1, image2)\n",
        "    return similarity_score"
      ],
      "metadata": {
        "id": "j7KwxICkbUYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 train_images와 test_images 비교하여 일치율 리스트 생성\n",
        "similarity_list = []\n",
        "for image1 in train_ori_images:\n",
        "    similarity_scores = [classify_images(image1, image2) for image2 in test_images]\n",
        "    similarity_list.append(similarity_scores)\n",
        "\n",
        "# 각 train 이미지에 대한  계산\n",
        "average_similarity_list = [np.mean(scores) for scores in similarity_list]\n",
        "\n",
        "# 전체데이터의 평균 일치율값\n",
        "average_similarity_total = np.mean(average_similarity_list)\n",
        "print(\"전체 Train 이미지에 대한 평균 일치율: {:.2f}%\".format(average_similarity_total * 100))"
      ],
      "metadata": {
        "id": "-7RwlieFhXT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이상값 탐색 (평균 일치율이 기준보다 낮은 값들)\n",
        "threshold = average_similarity_total\n",
        "outliers = [idx+1 for idx, score in enumerate(average_similarity_list) if score < threshold]\n",
        "\n",
        "# 이상값 개수와 해당 인덱스 출력\n",
        "print(\"이상값 개수:\", len(outliers))\n",
        "print(\"이상값의 인덱스:\", outliers)\n",
        "\n",
        "# 평균 일치율 데이터로 산점도 그래프 그리기\n",
        "plt.scatter(range(1, len(average_similarity_list) + 1), average_similarity_list)\n",
        "plt.scatter(outliers, [average_similarity_list[idx-1] for idx in outliers], color='red')\n",
        "plt.axhline(average_similarity_total, color='green', linestyle='--', label='평균 일치율')\n",
        "plt.xlabel('Train 이미지')\n",
        "plt.ylabel('평균 일치율')\n",
        "plt.title('Train 이미지에 대한 평균 일치율')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jCa2Z0SGkFnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤하게 이상값 이미지 하나 선택\n",
        "random_outlier_idx = random.choice(outliers) - 1  # 이상값 인덱스는 1부터 시작하므로 변환\n",
        "random_outlier_train_image = train_ori_images[random_outlier_idx]\n",
        "\n",
        "print(f\"랜덤 선택된 이상값 (Train 이미지 {random_outlier_idx + 1}) 출력:\")\n",
        "plt.imshow(random_outlier_train_image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# 이상값의 일치율 계산\n",
        "outlier_similarity = average_similarity_list[random_outlier_idx]\n",
        "print(f\"이상값의 일치율: {outlier_similarity:.2f}\")"
      ],
      "metadata": {
        "id": "VLV1eekdoKl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정상값 개수 계산\n",
        "normal_count = len(train_ori_images) - len(outliers)\n",
        "\n",
        "# 훈련 데이터의 전체 데이터 대비 이상치 비율 계산\n",
        "total_data_count = len(train_ori_images)\n",
        "outlier_ratio = (len(outliers) / total_data_count) * 100\n",
        "\n",
        "# 훈련 데이터의 이상값과 정상값 개수 비교\n",
        "print(\"훈련 데이터의 이상값 개수:\", len(outliers))\n",
        "print(\"훈련 데이터의 정상값 개수:\", normal_count)\n",
        "print(\"훈련 데이터의 이상치 비율:\", len(outliers) / 272)"
      ],
      "metadata": {
        "id": "9m6bqDj0opbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"원래 데이터의 이상값 개수:\", len(test_dir))\n",
        "print(\"원래 데이터의 정상값 개수:\", len(train_dir))\n",
        "print(\"원래 데이터의 이상치 비율:\", len(test_dir) / 272)"
      ],
      "metadata": {
        "id": "Za9rXzPCpqXF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}